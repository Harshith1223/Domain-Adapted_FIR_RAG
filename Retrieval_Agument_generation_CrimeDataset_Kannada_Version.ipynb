{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NgOsU_K38mGa"
   },
   "source": [
    "---\n",
    "\n",
    "$$\\boxed{\\color{pink}{\\text{Agentic AI Workshop Day-2}}}$$\n",
    "\n",
    "$${\\color{yellow}{\\underline{\\text{Theme}}}: \\text{retrieval augmented generation (RAG)}}$$\n",
    "\n",
    "$${\\color{yellow}{\\underline{\\text{Goal}}}: \\text{scale retrieval using RAG}}$$\n",
    "\n",
    "\n",
    "**Topics**:\n",
    "\n",
    "1. Understand why embeddings alone are not enough\n",
    "\n",
    "2. Build a retrieval pipeline using FAISS\n",
    "\n",
    "3. Connect retrieval → generation (RAG)\n",
    "\n",
    "4. Run local multilingual LLM inference\n",
    "\n",
    "5. Generate crime summaries\n",
    "\n",
    "6. Evaluate when RAG helps and when it fails\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bs3Dy2iWDYIn"
   },
   "source": [
    "---\n",
    "\n",
    "Import libraries\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1766120966170,
     "user": {
      "displayName": "S N S Acharya",
      "userId": "14786945180387920086"
     },
     "user_tz": -330
    },
    "id": "-1WVpij28mGe",
    "outputId": "bd8b4b94-160d-4464-bc7d-d907e4aeca45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.9.1+cpu\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import unicodedata\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O1ogwCX1-jvz"
   },
   "source": [
    "---\n",
    "\n",
    "Mount Google Drive if running in Colab\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31514,
     "status": "ok",
     "timestamp": 1766119157283,
     "user": {
      "displayName": "S N S Acharya",
      "userId": "14786945180387920086"
     },
     "user_tz": -330
    },
    "id": "I9zmBbC8-kpD",
    "outputId": "8c15d455-5121-4bdd-ed29-65516bb2a758"
   },
   "outputs": [],
   "source": [
    "## Mount Google drive folder if running in Colab\n",
    "if('google.colab' in sys.modules):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount = True)\n",
    "    DIR = '/content/drive/MyDrive/Colab Notebooks/MAHE/MSIS Coursework/OddSem2025MAHE/Share/Agentic Workshop/NoStudentAccess'\n",
    "    DATA_DIR = DIR + '/Data/'\n",
    "    !pip install faiss-cpu --quiet\n",
    "    os.chdir(DIR)\n",
    "else:\n",
    "    DATA_DIR = '../Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvWR_nLE_SQY"
   },
   "source": [
    "---\n",
    "\n",
    "Load Udupi crime data\n",
    "\n",
    "Expected CSV columns:\n",
    "\n",
    "- Crime Type\n",
    "- Location\n",
    "- Day of Week (label encoded: 0–6)\n",
    "- Time of Day (0–3)\n",
    "- Day\n",
    "- Month\n",
    "- Year\n",
    "- Crime Description (Kannada text)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "executionInfo": {
     "elapsed": 783,
     "status": "ok",
     "timestamp": 1766120841335,
     "user": {
      "displayName": "S N S Acharya",
      "userId": "14786945180387920086"
     },
     "user_tz": -330
    },
    "id": "IFH-H0KS8mGh",
    "outputId": "17d72e02-6a8f-4bc8-aae2-fe75c51d4f7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Udupi crime dataset\n",
      "-----------\n",
      "Number of records = 13457\n",
      "Number of features = 9\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Crime Type</th>\n",
       "      <th>Location</th>\n",
       "      <th>Day of Week</th>\n",
       "      <th>Time of Day</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Crime Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ಮಟ್ಕಾ ಜುಗಾರಿ ಪ್ರಕರಣ</td>\n",
       "      <td>ಗಂಗೊಳ್ಳಿ</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>ಭೀಮಶಂಕರ್ ಎಸ್ ಎಸ್ ಪಿ ಎಸ್ ಐ ಗಂಗೊಳ್ಳಿ ಪೊಲಿಸ್ ಠಾಣೆ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ಅಸ್ವಾಭಾವಿಕ ಮರಣ ಪ್ರಕರಣ</td>\n",
       "      <td>ಕೊಲ್ಲೂರು</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>ಪಿರ್ಯಾದಿದಾರರಾಧ ಶ್ರೀಮತಿ ಸಂಧ್ಯಾ ( 59 ವರ್ಷ) ಗಂಡ: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ಅಸ್ವಾಭಾವಿಕ ಮರಣ ಪ್ರಕರಣ</td>\n",
       "      <td>ಉಡುಪಿ</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>ಪಿರ್ಯಾದಿದಾರರಾದ ಕೆ ರಾಘವೇಂದ್ರ ಸರಳಾಯ(67), ತಂದೆ: ದ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ಮನುಷ್ಯ ಕಾಣೆ ಪ್ರಕರಣ</td>\n",
       "      <td>ಶಿರ್ವಾ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>ಪಿರ್ಯಾದಿದಾರರಾದ ಕಿಶೋರ್‌ಆಚಾರ್ಯ (31), ತಂದೆ:ಉಪೇಂದ್...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>ಅಪಘಾತ ಪ್ರಕರಣ</td>\n",
       "      <td>ಮಲ್ಪೆ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>ದಿನಾಂಕ 21/02/2020 ರಂದು 14:00 ಗಂಟೆಗೆ ಪಿರ್ಯಾದಿದಾ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index             Crime Type  Location  Day of Week  Time of Day   Day  \\\n",
       "0      0    ಮಟ್ಕಾ ಜುಗಾರಿ ಪ್ರಕರಣ  ಗಂಗೊಳ್ಳಿ          6.0          2.0  29.0   \n",
       "1      1  ಅಸ್ವಾಭಾವಿಕ ಮರಣ ಪ್ರಕರಣ  ಕೊಲ್ಲೂರು          6.0          0.0  29.0   \n",
       "2      2  ಅಸ್ವಾಭಾವಿಕ ಮರಣ ಪ್ರಕರಣ     ಉಡುಪಿ          6.0          1.0  29.0   \n",
       "3      3     ಮನುಷ್ಯ ಕಾಣೆ ಪ್ರಕರಣ    ಶಿರ್ವಾ          4.0          0.0  27.0   \n",
       "4      8           ಅಪಘಾತ ಪ್ರಕರಣ     ಮಲ್ಪೆ          5.0          1.0  21.0   \n",
       "\n",
       "   Month    Year                                  Crime Description  \n",
       "0    2.0  2020.0  ಭೀಮಶಂಕರ್ ಎಸ್ ಎಸ್ ಪಿ ಎಸ್ ಐ ಗಂಗೊಳ್ಳಿ ಪೊಲಿಸ್ ಠಾಣೆ...  \n",
       "1    2.0  2020.0  ಪಿರ್ಯಾದಿದಾರರಾಧ ಶ್ರೀಮತಿ ಸಂಧ್ಯಾ ( 59 ವರ್ಷ) ಗಂಡ: ...  \n",
       "2    2.0  2020.0  ಪಿರ್ಯಾದಿದಾರರಾದ ಕೆ ರಾಘವೇಂದ್ರ ಸರಳಾಯ(67), ತಂದೆ: ದ...  \n",
       "3    2.0  2020.0  ಪಿರ್ಯಾದಿದಾರರಾದ ಕಿಶೋರ್‌ಆಚಾರ್ಯ (31), ತಂದೆ:ಉಪೇಂದ್...  \n",
       "4    2.0  2020.0  ದಿನಾಂಕ 21/02/2020 ರಂದು 14:00 ಗಂಟೆಗೆ ಪಿರ್ಯಾದಿದಾ...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load Udupi crime data\n",
    "file = DATA_DIR+'UdupiCrimeData.csv'\n",
    "df= pd.read_csv(file, header = 0).dropna()\n",
    "df.reset_index(inplace = True)\n",
    "\n",
    "print('Udupi crime dataset')\n",
    "print('-----------')\n",
    "print('Number of records = %d'%(df.shape[0]))\n",
    "print('Number of features = %d\\n'%(df.shape[1]))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2sQlzNbL5MHX"
   },
   "source": [
    "---\n",
    "\n",
    "User-defined functions for normalizing Kannada text and tokenizing the resulting normalized text\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1766119229975,
     "user": {
      "displayName": "S N S Acharya",
      "userId": "14786945180387920086"
     },
     "user_tz": -330
    },
    "id": "xJyynXmH5MHY"
   },
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "  text = str(text)\n",
    "  # Remove every character that is NOT a Kannada character OR whitespace leaving only Kannada letters,\n",
    "  # vowels, and matras, and spaces and line breaks.\n",
    "  # Unicode range for Kannada: U+0C80 – U+0CFF, Devanagari: U+0900 – U+097F, Tamil: U+0B80 – U+0BFF\n",
    "  text = re.sub(r\"[^\\u0C80-\\u0CFF\\s]\", \"\", text)\n",
    "  # Replace one or more whitespace characters with a single space\n",
    "  text = re.sub(r\"\\s+\", \" \", text)\n",
    "  return text.strip()\n",
    "\n",
    "def tokenize(text):\n",
    "  return normalize_text(text).split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "In3OzzS85MHY"
   },
   "source": [
    "---\n",
    "\n",
    "Load pretrained embedding model and embed crime reports\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "1CjfV3VH5MHZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\Miniconda3\\envs\\agentic\\lib\\site-packages\\huggingface_hub\\file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46780260473844458c65592b5ab2ce7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/421 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedder = SentenceTransformer(\n",
    "    \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    ")\n",
    "\n",
    "texts = df[\"Crime Description\"].apply(normalize_text).tolist()\n",
    "\n",
    "# Embed crime reports into an embedding matrix\n",
    "\n",
    "X_embeddings = embedder.encode(texts,\n",
    "                               batch_size = 32,\n",
    "                               show_progress_bar = True,\n",
    "                               convert_to_numpy = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KcizYfp5MHZ"
   },
   "source": [
    "---\n",
    "\n",
    "**FAISS Index (Scalable Retrieval)**:\n",
    "\n",
    "- Fast Approximate Nearest Neighbor Search\n",
    "  \n",
    "- Optimized for large vector collections\n",
    "  \n",
    "- Used in real-world RAG systems\n",
    "  \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1766119306381,
     "user": {
      "displayName": "S N S Acharya",
      "userId": "14786945180387920086"
     },
     "user_tz": -330
    },
    "id": "bnjaxSOB6Rs3"
   },
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1766119308682,
     "user": {
      "displayName": "S N S Acharya",
      "userId": "14786945180387920086"
     },
     "user_tz": -330
    },
    "id": "NhvgzoJH5MHZ",
    "outputId": "7dbc114f-5510-46c0-93a0-8a58b86b0402"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13457"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Build FAISS index for embeddings built using\n",
    "## the pretrained model\n",
    "dim = X_embeddings.shape[1]\n",
    "\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index.add(X_embeddings)\n",
    "\n",
    "index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1766119310794,
     "user": {
      "displayName": "S N S Acharya",
      "userId": "14786945180387920086"
     },
     "user_tz": -330
    },
    "id": "dPgpBBxr5MHZ"
   },
   "outputs": [],
   "source": [
    "## User-defined function for retrieving top-5\n",
    "## similar embeddings\n",
    "def retrieve(query, k = 5):\n",
    "    query = normalize_text(query)\n",
    "    q_emb = embedder.encode([query], convert_to_numpy = True)\n",
    "    distances, indices = index.search(q_emb, k)\n",
    "    return df.iloc[indices[0]]['Crime Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1766119694144,
     "user": {
      "displayName": "S N S Acharya",
      "userId": "14786945180387920086"
     },
     "user_tz": -330
    },
    "id": "P1_SFauq5MHb",
    "outputId": "3e63a164-42b6-47e6-cb8a-1334c5d9a365"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947     ಪಿರ್ಯಾದಿದಾರರಾದ ಹರೀಶ್‌ ಶೆಟ್ಟಿ, ತಂದೆ: ಪರಮೇಶ್ವರ್ ...\n",
      "8440     ಬೆಳ್ಳೆ ಗ್ರಾಮ ಪಂಚಾಯತ್‌ ವ್ಯಾಪ್ತಿಯ ಕುಕ್ಕುದಕಟ್ಟೆ ಎ...\n",
      "6866     ಪಿರ್ಯಾದಿದಾರರಾದ ಆರ್. ವಸಂತ ಪ್ರಭು (46), ತಂದೆ:ಆರ್ ...\n",
      "13300    ಕಸ್ತೂರ್ಬಾ ಆಸ್ಪತ್ರೆ ಮಣಿಪಾಲ Cardiology Deptನಲ್ಲಿ...\n",
      "597      ಪಿರ್ಯಾದಿದಾರರಾದ ರಘುರಾಮ ಶೆಟ್ಟಿ(66) ತಂದೆ: ಶ್ಯಾಮ್ ...\n",
      "Name: Crime Description, dtype: object\n",
      "Top result 2947:\n",
      " ಪಿರ್ಯಾದಿದಾರರಾದ ಹರೀಶ್‌ ಶೆಟ್ಟಿ, ತಂದೆ: ಪರಮೇಶ್ವರ್ ಶೆಟ್ಟಿ, ವಾಸ: Yentuvaraha Mane, Via Kinnigoli, Mulki, ಏಲತ್ತೂರು ಗ್ರಾಮ, ಮಂಗಳೂರು ಇವರ ಅಣ್ಣ ದಿನೇಶ್‌ ಶೆಟ್ಟಿ(55) ರವರು ಮುಂಬೈಯಲ್ಲಿ ಕೆಲಸ ಮಾಡಿಕೊಂಡಿದ್ದವರು ದಿನಾಂಕ 22/03/2019 ರಂದು ರಾತ್ರಿ 8:30 ಗಂಟೆಗೆ ಸುಕುಮಾರ ತಿಂಗಳಾಯರೊಂದಿಗೆ ಮುಂಬೈಯಿಂದ ಮುಲ್ಕಿಗೆ ರೈಲಿನ್ನಲ್ಲಿ ಹೊರಟವರು ದಿನಾಂಕ 23/03/2019 ರಂದು ಬೆಳಿಗ್ಗೆ 5:30 ಗಂಟೆಗೆ ಇಂದ್ರಾಳಿ ರೈಲ್ವೆ ಸ್ಟೇಷನ್‌ ತಲುಪುವ ಮಾರ್ಗದಲ್ಲಿ ಹೃದಯಘಾತದಿಂದ ಮೃತಪಟ್ಟಿರುವುದಾಗಿದೆ. ಈ ಬಗ್ಗೆ ಮಣಿಪಾಲ ಪೊಲೀಸ್ ಠಾಣಾ ಯು.ಡಿ.ಆರ್ ಕ್ರಮಾಂಕ 18/2019 ಕಲಂ: 174 ಸಿ.ಆರ್.ಪಿ.ಸಿ ಯಂತೆ ಪ್ರಕರಣ ದಾಖಲಾಗಿರುತ್ತದೆ.\n"
     ]
    }
   ],
   "source": [
    "## Test retrieval and inspect the top result\n",
    "query = \"ಮೊಬೈಲ್ ಫೋನ್ ಕಳವು\"\n",
    "results = retrieve(query)\n",
    "print(results)\n",
    "print(f'Top result {results.index[0]}:\\n {results[results.index[0]]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rvgn4YCH8Dce"
   },
   "source": [
    "---\n",
    "\n",
    "Custom embedder module inherited from nn.Module\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1766120931402,
     "user": {
      "displayName": "S N S Acharya",
      "userId": "14786945180387920086"
     },
     "user_tz": -330
    },
    "id": "MuhTGfhQ5MHb"
   },
   "outputs": [],
   "source": [
    "## Simple embedder module\n",
    "class SimpleEmbedder(nn.Module):\n",
    "    def __init__(self, vocab_size, dim = 8):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x).mean(dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "executionInfo": {
     "elapsed": 1728,
     "status": "ok",
     "timestamp": 1766120934365,
     "user": {
      "displayName": "S N S Acharya",
      "userId": "14786945180387920086"
     },
     "user_tz": -330
    },
    "id": "vjx4zfnP5MHb"
   },
   "outputs": [],
   "source": [
    "## Build a dictionary of crime groups with the\n",
    "## keys as the crime types and the values as a list\n",
    "## of crime descriptions corresponding to that type\n",
    "crime_groups = defaultdict(list)\n",
    "\n",
    "# Voicabulary dictionary\n",
    "vocab_counter = Counter()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    tokens = tokenize(texts[index])\n",
    "    vocab_counter.update(tokens)\n",
    "    crime_groups[row['Crime Type']].append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1766120935403,
     "user": {
      "displayName": "S N S Acharya",
      "userId": "14786945180387920086"
     },
     "user_tz": -330
    },
    "id": "_7eo99rd5MHb"
   },
   "outputs": [],
   "source": [
    "# Build dictionaries for training the custom embedding model\n",
    "word2idx = {w:i for i, w in enumerate(vocab_counter.keys())}\n",
    "idx2word = {i:w for w, i in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1766120939195,
     "user": {
      "displayName": "S N S Acharya",
      "userId": "14786945180387920086"
     },
     "user_tz": -330
    },
    "id": "4fjZHQLfAgjy"
   },
   "outputs": [],
   "source": [
    "## User-defined function to encode the crime reports\n",
    "def encode_doc(tokens):\n",
    "    return [word2idx[t] for t in tokens if t in word2idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1766121191118,
     "user": {
      "displayName": "S N S Acharya",
      "userId": "14786945180387920086"
     },
     "user_tz": -330
    },
    "id": "p8Z3QWvV5MHb"
   },
   "outputs": [],
   "source": [
    "## Custom embedding model based on the crime type\n",
    "# Model\n",
    "embed_dim = 64\n",
    "model = SimpleEmbedder(len(word2idx), dim = embed_dim)\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-03)\n",
    "# Loss function\n",
    "loss_fn = nn.CosineEmbeddingLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 580772,
     "status": "ok",
     "timestamp": 1766121773147,
     "user": {
      "displayName": "S N S Acharya",
      "userId": "14786945180387920086"
     },
     "user_tz": -330
    },
    "id": "X0J2RHWG5MHc",
    "outputId": "3fd4a845-829a-4907-8bf1-81b1ff4a9c2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 88.9974\n",
      "Epoch 1 loss: 87.9765\n",
      "Epoch 2 loss: 84.8807\n",
      "Epoch 3 loss: 83.6857\n",
      "Epoch 4 loss: 79.1870\n",
      "Epoch 5 loss: 78.3373\n",
      "Epoch 6 loss: 75.4940\n",
      "Epoch 7 loss: 77.2715\n",
      "Epoch 8 loss: 70.3584\n",
      "Epoch 9 loss: 71.5190\n",
      "Epoch 10 loss: 71.5530\n",
      "Epoch 11 loss: 69.2210\n",
      "Epoch 12 loss: 69.0694\n",
      "Epoch 13 loss: 65.8411\n",
      "Epoch 14 loss: 66.9930\n",
      "Epoch 15 loss: 62.5341\n",
      "Epoch 16 loss: 64.8823\n",
      "Epoch 17 loss: 62.0176\n",
      "Epoch 18 loss: 58.2315\n",
      "Epoch 19 loss: 57.2337\n",
      "Epoch 20 loss: 59.7102\n",
      "Epoch 21 loss: 56.2805\n",
      "Epoch 22 loss: 58.0170\n",
      "Epoch 23 loss: 56.5707\n",
      "Epoch 24 loss: 54.6838\n",
      "Epoch 25 loss: 52.4883\n",
      "Epoch 26 loss: 53.7274\n",
      "Epoch 27 loss: 53.0932\n",
      "Epoch 28 loss: 50.1910\n",
      "Epoch 29 loss: 50.8321\n",
      "Epoch 30 loss: 49.0134\n",
      "Epoch 31 loss: 48.1353\n",
      "Epoch 32 loss: 51.4306\n",
      "Epoch 33 loss: 44.6991\n",
      "Epoch 34 loss: 47.6616\n",
      "Epoch 35 loss: 45.8824\n",
      "Epoch 36 loss: 48.0003\n",
      "Epoch 37 loss: 47.1835\n",
      "Epoch 38 loss: 45.2170\n",
      "Epoch 39 loss: 42.7781\n",
      "Epoch 40 loss: 47.7315\n",
      "Epoch 41 loss: 44.8473\n",
      "Epoch 42 loss: 46.1129\n",
      "Epoch 43 loss: 41.1675\n",
      "Epoch 44 loss: 43.6246\n",
      "Epoch 45 loss: 41.9218\n",
      "Epoch 46 loss: 39.0985\n",
      "Epoch 47 loss: 41.4857\n",
      "Epoch 48 loss: 40.8794\n",
      "Epoch 49 loss: 40.9312\n",
      "Epoch 50 loss: 42.7429\n",
      "Epoch 51 loss: 42.8200\n",
      "Epoch 52 loss: 37.7691\n",
      "Epoch 53 loss: 37.3927\n",
      "Epoch 54 loss: 38.4702\n",
      "Epoch 55 loss: 39.4181\n",
      "Epoch 56 loss: 35.8366\n",
      "Epoch 57 loss: 34.3035\n",
      "Epoch 58 loss: 37.8372\n",
      "Epoch 59 loss: 38.1337\n",
      "Epoch 60 loss: 37.8298\n",
      "Epoch 61 loss: 36.5862\n",
      "Epoch 62 loss: 35.5950\n",
      "Epoch 63 loss: 34.9346\n",
      "Epoch 64 loss: 32.4429\n",
      "Epoch 65 loss: 39.3752\n",
      "Epoch 66 loss: 31.9184\n",
      "Epoch 67 loss: 38.4055\n",
      "Epoch 68 loss: 35.1785\n",
      "Epoch 69 loss: 31.9080\n",
      "Epoch 70 loss: 35.2331\n",
      "Epoch 71 loss: 33.8207\n",
      "Epoch 72 loss: 35.2962\n",
      "Epoch 73 loss: 31.6372\n",
      "Epoch 74 loss: 32.5008\n",
      "Epoch 75 loss: 34.8878\n",
      "Epoch 76 loss: 33.4585\n",
      "Epoch 77 loss: 30.1394\n",
      "Epoch 78 loss: 34.3717\n",
      "Epoch 79 loss: 31.6205\n",
      "Epoch 80 loss: 30.4334\n",
      "Epoch 81 loss: 29.4106\n",
      "Epoch 82 loss: 32.1042\n",
      "Epoch 83 loss: 29.9158\n",
      "Epoch 84 loss: 30.3707\n",
      "Epoch 85 loss: 28.8807\n",
      "Epoch 86 loss: 28.3177\n",
      "Epoch 87 loss: 30.3765\n",
      "Epoch 88 loss: 31.6185\n",
      "Epoch 89 loss: 29.9264\n",
      "Epoch 90 loss: 30.8160\n",
      "Epoch 91 loss: 27.6374\n",
      "Epoch 92 loss: 30.2659\n",
      "Epoch 93 loss: 26.5489\n",
      "Epoch 94 loss: 29.9284\n",
      "Epoch 95 loss: 28.5618\n",
      "Epoch 96 loss: 29.9421\n",
      "Epoch 97 loss: 29.0103\n",
      "Epoch 98 loss: 24.7341\n",
      "Epoch 99 loss: 27.9196\n"
     ]
    }
   ],
   "source": [
    "## Custom embedding training loop\n",
    "num_epochs = 100\n",
    "epoch_loss = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for crime_type, docs in crime_groups.items():\n",
    "        # If a crime type has only one crime description\n",
    "        # then no contribution to training\n",
    "        if len(docs) < 2:\n",
    "            continue\n",
    "\n",
    "        # Pull tokens for a positive pair\n",
    "        d1_tokens, d2_tokens = random.sample(docs, 2)\n",
    "\n",
    "        # Pull tokens for a negative pair\n",
    "        neg_crime = random.choice([ct for ct in crime_groups.keys() if ct != crime_type])\n",
    "        d3_tokens = random.choice(crime_groups[neg_crime])\n",
    "\n",
    "        # Encode the positive and negative pairs of documents\n",
    "        d1 = torch.tensor(encode_doc(d1_tokens))\n",
    "        d2 = torch.tensor(encode_doc(d2_tokens))\n",
    "        d3 = torch.tensor(encode_doc(d3_tokens))\n",
    "\n",
    "        # Forward pass\n",
    "        e1 = model(d1)\n",
    "        e2 = model(d2)\n",
    "        e3 = model(d3)\n",
    "\n",
    "        # Losses\n",
    "        pos_label = torch.tensor(1.0)\n",
    "        neg_label = torch.tensor(-1.0)\n",
    "        loss_pos = loss_fn(e1, e2, pos_label)\n",
    "        loss_neg = loss_fn(e1, e3, neg_label)\n",
    "        loss = loss_pos + loss_neg\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    epoch_loss.append(total_loss)\n",
    "    print(f'Epoch {epoch} loss: {total_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "executionInfo": {
     "elapsed": 235,
     "status": "ok",
     "timestamp": 1766121952842,
     "user": {
      "displayName": "S N S Acharya",
      "userId": "14786945180387920086"
     },
     "user_tz": -330
    },
    "id": "pISpwhq3BE1r",
    "outputId": "c70488a5-c471-4367-cd66-e2fd0b50951f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plot loss as a function of epoch:\n",
    "fig, ax = plt.subplots(1, 1, figsize = (4, 4))\n",
    "fig.tight_layout(pad = 4.0)\n",
    "ax.plot(epoch_loss, 'b')\n",
    "ax.set_xlabel('Epoch', fontsize = 12)\n",
    "ax.set_ylabel('Loss value', fontsize = 12)\n",
    "ax.set_title('Loss vs. Epoch', fontsize = 14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "executionInfo": {
     "elapsed": 2957,
     "status": "ok",
     "timestamp": 1766121974027,
     "user": {
      "displayName": "S N S Acharya",
      "userId": "14786945180387920086"
     },
     "user_tz": -330
    },
    "id": "lbcm9G1k5MHc"
   },
   "outputs": [],
   "source": [
    "## Generate custom embeddings for the crime reports\n",
    "\n",
    "# Create empty embeddings matrix\n",
    "X_customembeddings = np.empty((df.shape[0], embed_dim))\n",
    "\n",
    "# Populate the embeddings matrix with the custom embeddings\n",
    "for i in range(df.shape[0]):\n",
    "  X_customembeddings[i] = model.forward(torch.tensor(encode_doc(texts[i]))).detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1766121976428,
     "user": {
      "displayName": "S N S Acharya",
      "userId": "14786945180387920086"
     },
     "user_tz": -330
    },
    "id": "PHT006OW5MHc",
    "outputId": "c90d719f-4f41-41d7-a0ed-18e95d772f01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13457"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build FAISS index for embeddings built using\n",
    "## the custom embedding model\n",
    "dim = X_customembeddings.shape[1]\n",
    "\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index.add(X_customembeddings)\n",
    "\n",
    "index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1766121978404,
     "user": {
      "displayName": "S N S Acharya",
      "userId": "14786945180387920086"
     },
     "user_tz": -330
    },
    "id": "0pI9Fe175MHc"
   },
   "outputs": [],
   "source": [
    "## User-defined function for retrieving top-5\n",
    "## similar embeddings\n",
    "def semantic_search(query, k = 5):\n",
    "  query = normalize_text(query)\n",
    "  q_emb = model.forward(torch.tensor(encode_doc(query))).detach().numpy().reshape(1, -1)\n",
    "  distances, indices = index.search(q_emb, k)\n",
    "  return df.iloc[indices[0]]['Crime Description']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1766121994204,
     "user": {
      "displayName": "S N S Acharya",
      "userId": "14786945180387920086"
     },
     "user_tz": -330
    },
    "id": "meGZCUo85MHc",
    "outputId": "080221cc-d3ea-414d-85e8-6cd1aa698ff2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10730    ದಿನಾಂಕ 30/06/2016 ರಂದು 15:00 ಗಂಟೆಗೆ ಪಿರ್ಯಾದಿದಾ...\n",
      "13393    ದಿನಾಂಕ. 11/08/2015 ರಂದು ಮದ್ಯಾಹ್ನ 2:30 ಗಂಟೆಯ ಸಮ...\n",
      "11901    ಅಬ್ದುಲ್‌ ರೆಹಮಾನ್‌ ಪ್ರಾಯ 31 ವರ್ಷ ತಂದೆ: ಅಬ್ದುಲ್‌...\n",
      "11197    ದಿನಾಂಕ 05/05/2016 ರಂದು ಸಂಜೆ 6:00 ಗಂಟೆಯಿಂದ 06/0...\n",
      "13075    ದಿನಾಂಕ 05/10/15 ರಂದು ಬೆಳಿಗ್ಗೆ 10:00 ಗಂಟೆಯಿಂದ ಮ...\n",
      "Name: Crime Description, dtype: object\n",
      "Top result 10730:\n",
      " ದಿನಾಂಕ 30/06/2016 ರಂದು 15:00 ಗಂಟೆಗೆ ಪಿರ್ಯಾದಿದಾರರಾದ ಅನಿತಾ.ಎಲ್, ಕುಕ್ಯಾನ್ (46), ಗಂಡ: ಲಕ್ಷ್ಮಣ ಕುಕ್ಯಾನ್ , ವಾಸ: ಪಡು ಇನ್ನಾ ಪೋಸ್ಟ್. ಇನ್ನಾ , ಕಾರ್ಕಳ ತಾಲೂಕು ಇವರ ಮಗನಾದ ಅನಿಲ್ ಎಂಬುವವರು ಪಲಿಮಾರು ಚರ್ಚ್ ಬಳಿ ಮೋಹನ್ ಆಚಾರಿ ಎಂಬುವವರ ಮನೆಯ ಬಳಿ ಮೋಟಾರು ಸೈಕಲ್ ನಲ್ಲಿ ಬರುತ್ತಿದ್ದಾಗ ಮೂಡು ಪಲಿಮಾರಿನ ವಾಸಿ ಆರೋಪಿ ಮಹಮ್ಮದ್ ಶಿನಾನ್ ಎಂಬುವವನು ಆತನ ಬೈಕನ್ನು ರಸ್ತೆಗೆ ಅಡ್ಡ ಇಟ್ಟು ಅನಿಲನನ್ನು ತಡೆದು ನಿನಗೆ ನಿಧಾನ ಹೋಗಲಿಕ್ಕೆ ಆಗುವುದಿಲ್ಲವಾ ಎಂದು ಹೇಳಿದ್ದು, ಅನಿಲನು ಮನೆಗೆ ಬಂದು ತಾಯಿಯವರಿಗೆ ವಿಷಯ ತಿಳಿಸಿ ಮಲಗಿದ್ದು, ನಂತರ 15:20 ಗಂಟೆಗೆ ಮೂಡು ಪಲಿಮಾರಿನ ನಿವಾಸಿಗಳಾದ ನಾಸಿರ್, ಮನ್ಸೂರ್, ಸಿನಾನ್, ಅಮೀರ್ , ತೌಸೀಫ್ ಮತ್ತು ಜೈನುದ್ದೀನ್ ಎಂಬುಬವರು ಕೆಎ-20-ಇಹೆಚ್-5484 ಹಾಗೂ ಕೆಎ-21 ನೋಂದಣಿ ಹೊಂದಿದ್ದ 2 ಮೋಟಾರು ಸೈಕಲ್ ನಲ್ಲಿ ಅನಿತಾ.ಎಲ್, ಕುಕ್ಯಾನ್ ರಚರ ಮನೆ ಕಂಪೌಂಡಿನ ಒಳಗೆ ಪ್ರವೇಶಿಸಿ ಮನೆಯ ಬಾಗಿಲ ಬಳಿ ಬಂದು ಅನಿಲ ಎಲ್ಲಿ ಎಂದು ಕೇಳಿ ಮನೆಯ ಒಳಗೆ ಪ್ರವೇಶಿಸಲು ನೋಡಿ, ಅನಿತಾ.ಎಲ್, ಕುಕ್ಯಾನ್ ರವರನ್ನು ತಳ್ಳಿರುತ್ತಾರೆ. ಅವರ ಮಾತು ಕೇಳಿ ಹೊರ ಬಂದ ಅನಿಲ್ ರವರಿಗೆ ಮನ್ಸೂರನ್ನು ತುಳಿದಿರುತ್ತಾನೆ. ಅನಿತಾ.ಎಲ್, ಕುಕ್ಯಾನ್ ರವರು ಮಗನನ್ನು ತಡೆಯಲು ಹೋದಾಗ ತೌಸೀಫನು ಮೈಗೆ ಕೈ ಹಾಕಿ ಅನಿಲ್ ನಿಗೆ ಹೊಡೆದಿರುತ್ತಾರೆ. ನಂತರ ಅನಿಲ್ ನನ್ನು ಉದ್ದೇಶಿಸಿ ಅವಾಚ್ಯ ಶಬ್ದದಿಂದ ಬೈದು ನೋಡಿ ಕೊಳ್ಳುತ್ತೇನೆ ಎಂದು ಬೆದರಿಕೆ ಹಾಕಿದ್ದು, ಅಕ್ಕ ಪಕ್ಕದ ಜನರು ಬರುವುದನ್ನು ನೋಡಿ ನಿನ್ನನ್ನು ಬಿಡುವುದಿಲ್ಲ ನೋಡಿ ಕೊಳ್ಳುತ್ತೇನೆ ಎಂದು ಅಲ್ಲಿಂದ ಬೈಕ್ ನಲ್ಲಿ ಹೊರಟು ಹೋಗಿರುತ್ತಾರೆ. ಈ ಬಗ್ಗೆ ಪಡುಬಿದ್ರಿ ಪೊಲೀಸ್ ಠಾಣೆ ಅಪರಾಧ ಕ್ರಮಾಂಕ 112/2016 ಕಲಂ: 341. 143, 147, 323, 354 (ಬಿ), 504, 506 ಜೊತೆಗೆ 149 ಐಪಿಸಿಯಂತೆ ಪ್ರಕರಣ ದಾಖಲಾಗಿರುತ್ತದೆ.\n"
     ]
    }
   ],
   "source": [
    "## Test retrieval and inspect the top result\n",
    "query = \"ಮೊಬೈಲ್ ಫೋನ್ ಕಳವು\"\n",
    "results = semantic_search(query)\n",
    "print(results)\n",
    "print(f'Top result {results.index[0]}:\\n {results[results.index[0]]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-PYNVIR5MHc"
   },
   "source": [
    "---\n",
    "\n",
    "We move from retrieval to retrieval augmented generation (RAG) using the open source 4-bit quantized Qwen2 LLM $$\\color{yellow}{\\text{qwen2-1\\_5b-instruct-q4\\_0.gguf}}$$ available at  https://huggingface.co/Qwen/Qwen2-1.5B-Instruct-GGUF\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "1zXQOmqt5MHc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 26 key-value pairs and 338 tensors from ../Models/qwen2-1_5b-instruct-q4_0.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = qwen2\n",
      "llama_model_loader: - kv   1:                               general.name str              = qwen2-1_5b-instruct\n",
      "llama_model_loader: - kv   2:                          qwen2.block_count u32              = 28\n",
      "llama_model_loader: - kv   3:                       qwen2.context_length u32              = 32768\n",
      "llama_model_loader: - kv   4:                     qwen2.embedding_length u32              = 1536\n",
      "llama_model_loader: - kv   5:                  qwen2.feed_forward_length u32              = 8960\n",
      "llama_model_loader: - kv   6:                 qwen2.attention.head_count u32              = 12\n",
      "llama_model_loader: - kv   7:              qwen2.attention.head_count_kv u32              = 2\n",
      "llama_model_loader: - kv   8:                       qwen2.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv   9:     qwen2.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 2\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  12:                         tokenizer.ggml.pre str              = qwen2\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,151936]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,151936]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.merges arr[str,151387]  = [\"Ġ Ġ\", \"ĠĠ ĠĠ\", \"i n\", \"Ġ t\",...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 151645\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.padding_token_id u32              = 151643\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 151643\n",
      "llama_model_loader: - kv  19:                    tokenizer.chat_template str              = {% for message in messages %}{% if lo...\n",
      "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = false\n",
      "llama_model_loader: - kv  21:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  22:                      quantize.imatrix.file str              = ../Qwen2/gguf/qwen2-1_5b-imatrix/imat...\n",
      "llama_model_loader: - kv  23:                   quantize.imatrix.dataset str              = ../sft_2406.txt\n",
      "llama_model_loader: - kv  24:             quantize.imatrix.entries_count i32              = 196\n",
      "llama_model_loader: - kv  25:              quantize.imatrix.chunks_count i32              = 1937\n",
      "llama_model_loader: - type  f32:  141 tensors\n",
      "llama_model_loader: - type q4_0:  193 tensors\n",
      "llama_model_loader: - type q4_1:    3 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q4_0\n",
      "print_info: file size   = 888.43 MiB (4.83 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 2\n",
      "load: control token: 151644 '<|im_start|>' is not marked as EOG\n",
      "load: printing all EOG tokens:\n",
      "load:   - 151643 ('<|endoftext|>')\n",
      "load:   - 151645 ('<|im_end|>')\n",
      "load: special tokens cache size = 293\n",
      "load: token to piece cache size = 0.9338 MB\n",
      "print_info: arch             = qwen2\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 32768\n",
      "print_info: n_embd           = 1536\n",
      "print_info: n_layer          = 28\n",
      "print_info: n_head           = 12\n",
      "print_info: n_head_kv        = 2\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: is_swa_any       = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 6\n",
      "print_info: n_embd_k_gqa     = 256\n",
      "print_info: n_embd_v_gqa     = 256\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-06\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 8960\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = -1\n",
      "print_info: rope type        = 2\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 1000000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 32768\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: model type       = 1.5B\n",
      "print_info: model params     = 1.54 B\n",
      "print_info: general.name     = qwen2-1_5b-instruct\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 151936\n",
      "print_info: n_merges         = 151387\n",
      "print_info: BOS token        = 151643 '<|endoftext|>'\n",
      "print_info: EOS token        = 151645 '<|im_end|>'\n",
      "print_info: EOT token        = 151645 '<|im_end|>'\n",
      "print_info: PAD token        = 151643 '<|endoftext|>'\n",
      "print_info: LF token         = 198 'Ċ'\n",
      "print_info: EOG token        = 151643 '<|endoftext|>'\n",
      "print_info: EOG token        = 151645 '<|im_end|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  12 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  13 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  14 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  15 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  16 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  17 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  18 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  19 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  20 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  21 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  22 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  23 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  24 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  25 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  26 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  27 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  28 assigned to device CPU, is_swa = 0\n",
      "load_tensors: tensor 'token_embd.weight' (q6_K) (and 145 others) cannot be used with preferred buffer type CPU_REPACK, using CPU instead\n",
      "load_tensors:   CPU_REPACK model buffer size =   680.70 MiB\n",
      "load_tensors:   CPU_Mapped model buffer size =   888.43 MiB\n",
      "repack: repack tensor blk.0.attn_q.weight with q4_0_8x8\n",
      "repack: repack tensor blk.0.attn_k.weight with q4_0_8x8\n",
      "repack: repack tensor blk.0.attn_v.weight with q4_0_8x8\n",
      "repack: repack tensor blk.0.attn_output.weight with q4_0_8x8\n",
      "repack: repack tensor blk.0.ffn_gate.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.0.ffn_up.weight with q4_0_8x8\n",
      "repack: repack tensor blk.1.attn_q.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.1.attn_k.weight with q4_0_8x8\n",
      "repack: repack tensor blk.1.attn_v.weight with q4_0_8x8\n",
      "repack: repack tensor blk.1.attn_output.weight with q4_0_8x8\n",
      "repack: repack tensor blk.1.ffn_gate.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.1.ffn_up.weight with q4_0_8x8\n",
      "repack: repack tensor blk.2.attn_q.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.2.attn_k.weight with q4_0_8x8\n",
      "repack: repack tensor blk.2.attn_v.weight with q4_0_8x8\n",
      "repack: repack tensor blk.2.attn_output.weight with q4_0_8x8\n",
      "repack: repack tensor blk.2.ffn_gate.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.2.ffn_down.weight with q4_0_8x8\n",
      "repack: repack tensor blk.2.ffn_up.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.3.attn_q.weight with q4_0_8x8\n",
      "repack: repack tensor blk.3.attn_k.weight with q4_0_8x8\n",
      "repack: repack tensor blk.3.attn_v.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.3.attn_output.weight with q4_0_8x8\n",
      "repack: repack tensor blk.3.ffn_gate.weight with q4_0_8x8\n",
      "repack: repack tensor blk.3.ffn_down.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.3.ffn_up.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.4.attn_q.weight with q4_0_8x8\n",
      "repack: repack tensor blk.4.attn_k.weight with q4_0_8x8\n",
      "repack: repack tensor blk.4.attn_v.weight with q4_0_8x8\n",
      "repack: repack tensor blk.4.attn_output.weight with q4_0_8x8\n",
      "repack: repack tensor blk.4.ffn_gate.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.4.ffn_down.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.4.ffn_up.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.5.attn_q.weight with q4_0_8x8\n",
      "repack: repack tensor blk.5.attn_k.weight with q4_0_8x8\n",
      "repack: repack tensor blk.5.attn_v.weight with q4_0_8x8\n",
      "repack: repack tensor blk.5.attn_output.weight with q4_0_8x8\n",
      "repack: repack tensor blk.5.ffn_gate.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.5.ffn_down.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.5.ffn_up.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.6.attn_q.weight with q4_0_8x8\n",
      "repack: repack tensor blk.6.attn_k.weight with q4_0_8x8\n",
      "repack: repack tensor blk.6.attn_v.weight with q4_0_8x8\n",
      "repack: repack tensor blk.6.attn_output.weight with q4_0_8x8\n",
      "repack: repack tensor blk.6.ffn_gate.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.6.ffn_down.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.6.ffn_up.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.7.attn_q.weight with q4_0_8x8\n",
      "repack: repack tensor blk.7.attn_k.weight with q4_0_8x8\n",
      "repack: repack tensor blk.7.attn_v.weight with q4_0_8x8\n",
      "repack: repack tensor blk.7.attn_output.weight with q4_0_8x8\n",
      "repack: repack tensor blk.7.ffn_gate.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.7.ffn_down.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.7.ffn_up.weight with q4_0_8x8\n",
      "repack: repack tensor blk.8.attn_q.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.8.attn_k.weight with q4_0_8x8\n",
      "repack: repack tensor blk.8.attn_v.weight with q4_0_8x8\n",
      "repack: repack tensor blk.8.attn_output.weight with q4_0_8x8\n",
      "repack: repack tensor blk.8.ffn_gate.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.8.ffn_down.weight with q4_0_8x8\n",
      "repack: repack tensor blk.8.ffn_up.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.9.attn_q.weight with q4_0_8x8\n",
      "repack: repack tensor blk.9.attn_k.weight with q4_0_8x8\n",
      "repack: repack tensor blk.9.attn_v.weight with q4_0_8x8\n",
      "repack: repack tensor blk.9.attn_output.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.9.ffn_gate.weight with q4_0_8x8\n",
      "repack: repack tensor blk.9.ffn_down.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.9.ffn_up.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.10.attn_q.weight with q4_0_8x8\n",
      "repack: repack tensor blk.10.attn_k.weight with q4_0_8x8\n",
      "repack: repack tensor blk.10.attn_v.weight with q4_0_8x8\n",
      "repack: repack tensor blk.10.attn_output.weight with q4_0_8x8\n",
      "repack: repack tensor blk.10.ffn_gate.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.10.ffn_up.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.11.attn_q.weight with q4_0_8x8\n",
      "repack: repack tensor blk.11.attn_k.weight with q4_0_8x8\n",
      "repack: repack tensor blk.11.attn_v.weight with q4_0_8x8\n",
      "repack: repack tensor blk.11.attn_output.weight with q4_0_8x8\n",
      "repack: repack tensor blk.11.ffn_gate.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.11.ffn_down.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.11.ffn_up.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.12.attn_q.weight with q4_0_8x8\n",
      "repack: repack tensor blk.12.attn_k.weight with q4_0_8x8\n",
      "repack: repack tensor blk.12.attn_v.weight with q4_0_8x8\n",
      "repack: repack tensor blk.12.attn_output.weight with q4_0_8x8\n",
      "repack: repack tensor blk.12.ffn_gate.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.12.ffn_down.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.12.ffn_up.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.13.attn_q.weight with q4_0_8x8\n",
      "repack: repack tensor blk.13.attn_k.weight with q4_0_8x8\n",
      "repack: repack tensor blk.13.attn_v.weight with q4_0_8x8\n",
      "repack: repack tensor blk.13.attn_output.weight with q4_0_8x8\n",
      "repack: repack tensor blk.13.ffn_gate.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.13.ffn_down.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.13.ffn_up.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.14.attn_q.weight with q4_0_8x8\n",
      "repack: repack tensor blk.14.attn_k.weight with q4_0_8x8\n",
      "repack: repack tensor blk.14.attn_v.weight with q4_0_8x8\n",
      "repack: repack tensor blk.14.attn_output.weight with q4_0_8x8\n",
      "repack: repack tensor blk.14.ffn_gate.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.14.ffn_down.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.14.ffn_up.weight with q4_0_8x8\n",
      "repack: repack tensor blk.15.attn_q.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.15.attn_k.weight with q4_0_8x8\n",
      "repack: repack tensor blk.15.attn_v.weight with q4_0_8x8\n",
      "repack: repack tensor blk.15.attn_output.weight with q4_0_8x8\n",
      "repack: repack tensor blk.15.ffn_gate.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.15.ffn_down.weight with q4_0_8x8\n",
      "repack: repack tensor blk.15.ffn_up.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.16.attn_q.weight with q4_0_8x8\n",
      "repack: repack tensor blk.16.attn_k.weight with q4_0_8x8\n",
      "repack: repack tensor blk.16.attn_v.weight with q4_0_8x8\n",
      "repack: repack tensor blk.16.attn_output.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.16.ffn_gate.weight with q4_0_8x8\n",
      "repack: repack tensor blk.16.ffn_down.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.16.ffn_up.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.17.attn_q.weight with q4_0_8x8\n",
      "repack: repack tensor blk.17.attn_k.weight with q4_0_8x8\n",
      "repack: repack tensor blk.17.attn_v.weight with q4_0_8x8\n",
      "repack: repack tensor blk.17.attn_output.weight with q4_0_8x8\n",
      "repack: repack tensor blk.17.ffn_gate.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.17.ffn_down.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.17.ffn_up.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.18.attn_q.weight with q4_0_8x8\n",
      "repack: repack tensor blk.18.attn_k.weight with q4_0_8x8\n",
      "repack: repack tensor blk.18.attn_v.weight with q4_0_8x8\n",
      "repack: repack tensor blk.18.attn_output.weight with q4_0_8x8\n",
      "repack: repack tensor blk.18.ffn_gate.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.18.ffn_down.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.18.ffn_up.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.19.attn_q.weight with q4_0_8x8\n",
      "repack: repack tensor blk.19.attn_k.weight with q4_0_8x8\n",
      "repack: repack tensor blk.19.attn_v.weight with q4_0_8x8\n",
      "repack: repack tensor blk.19.attn_output.weight with q4_0_8x8\n",
      "repack: repack tensor blk.19.ffn_gate.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.19.ffn_down.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.19.ffn_up.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.20.attn_q.weight with q4_0_8x8\n",
      "repack: repack tensor blk.20.attn_k.weight with q4_0_8x8\n",
      "repack: repack tensor blk.20.attn_v.weight with q4_0_8x8\n",
      "repack: repack tensor blk.20.attn_output.weight with q4_0_8x8\n",
      "repack: repack tensor blk.20.ffn_gate.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.20.ffn_down.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.20.ffn_up.weight with q4_0_8x8\n",
      "repack: repack tensor blk.21.attn_q.weight with q4_0_8x8\n",
      "repack: repack tensor blk.21.attn_k.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.21.attn_v.weight with q4_0_8x8\n",
      "repack: repack tensor blk.21.attn_output.weight with q4_0_8x8\n",
      "repack: repack tensor blk.21.ffn_gate.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.21.ffn_down.weight with q4_0_8x8\n",
      "repack: repack tensor blk.21.ffn_up.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.22.attn_q.weight with q4_0_8x8\n",
      "repack: repack tensor blk.22.attn_k.weight with q4_0_8x8\n",
      "repack: repack tensor blk.22.attn_v.weight with q4_0_8x8\n",
      "repack: repack tensor blk.22.attn_output.weight with q4_0_8x8\n",
      "repack: repack tensor blk.22.ffn_gate.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.22.ffn_down.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.22.ffn_up.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.23.attn_q.weight with q4_0_8x8\n",
      "repack: repack tensor blk.23.attn_k.weight with q4_0_8x8\n",
      "repack: repack tensor blk.23.attn_v.weight with q4_0_8x8\n",
      "repack: repack tensor blk.23.attn_output.weight with q4_0_8x8\n",
      "repack: repack tensor blk.23.ffn_gate.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.23.ffn_down.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.23.ffn_up.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.24.attn_q.weight with q4_0_8x8\n",
      "repack: repack tensor blk.24.attn_k.weight with q4_0_8x8\n",
      "repack: repack tensor blk.24.attn_v.weight with q4_0_8x8\n",
      "repack: repack tensor blk.24.attn_output.weight with q4_0_8x8\n",
      "repack: repack tensor blk.24.ffn_gate.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.24.ffn_down.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.24.ffn_up.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.25.attn_q.weight with q4_0_8x8\n",
      "repack: repack tensor blk.25.attn_k.weight with q4_0_8x8\n",
      "repack: repack tensor blk.25.attn_v.weight with q4_0_8x8\n",
      "repack: repack tensor blk.25.attn_output.weight with q4_0_8x8\n",
      "repack: repack tensor blk.25.ffn_gate.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.25.ffn_down.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.25.ffn_up.weight with q4_0_8x8\n",
      "repack: repack tensor blk.26.attn_q.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.26.attn_k.weight with q4_0_8x8\n",
      "repack: repack tensor blk.26.attn_v.weight with q4_0_8x8\n",
      "repack: repack tensor blk.26.attn_output.weight with q4_0_8x8\n",
      "repack: repack tensor blk.26.ffn_gate.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.26.ffn_down.weight with q4_0_8x8\n",
      "repack: repack tensor blk.26.ffn_up.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.27.attn_q.weight with q4_0_8x8\n",
      "repack: repack tensor blk.27.attn_k.weight with q4_0_8x8\n",
      "repack: repack tensor blk.27.attn_v.weight with q4_0_8x8\n",
      "repack: repack tensor blk.27.attn_output.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.27.ffn_gate.weight with q4_0_8x8\n",
      "repack: repack tensor blk.27.ffn_down.weight with q4_0_8x8\n",
      ".repack: repack tensor blk.27.ffn_up.weight with q4_0_8x8\n",
      ".....\n",
      "llama_context: constructing llama_context\n",
      "llama_context: n_seq_max     = 1\n",
      "llama_context: n_ctx         = 5096\n",
      "llama_context: n_ctx_per_seq = 5096\n",
      "llama_context: n_batch       = 512\n",
      "llama_context: n_ubatch      = 512\n",
      "llama_context: causal_attn   = 1\n",
      "llama_context: flash_attn    = 0\n",
      "llama_context: kv_unified    = false\n",
      "llama_context: freq_base     = 1000000.0\n",
      "llama_context: freq_scale    = 1\n",
      "llama_context: n_ctx_per_seq (5096) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
      "set_abort_callback: call\n",
      "llama_context:        CPU  output buffer size =     0.58 MiB\n",
      "create_memory: n_ctx = 5120 (padded)\n",
      "llama_kv_cache_unified: layer   0: dev = CPU\n",
      "llama_kv_cache_unified: layer   1: dev = CPU\n",
      "llama_kv_cache_unified: layer   2: dev = CPU\n",
      "llama_kv_cache_unified: layer   3: dev = CPU\n",
      "llama_kv_cache_unified: layer   4: dev = CPU\n",
      "llama_kv_cache_unified: layer   5: dev = CPU\n",
      "llama_kv_cache_unified: layer   6: dev = CPU\n",
      "llama_kv_cache_unified: layer   7: dev = CPU\n",
      "llama_kv_cache_unified: layer   8: dev = CPU\n",
      "llama_kv_cache_unified: layer   9: dev = CPU\n",
      "llama_kv_cache_unified: layer  10: dev = CPU\n",
      "llama_kv_cache_unified: layer  11: dev = CPU\n",
      "llama_kv_cache_unified: layer  12: dev = CPU\n",
      "llama_kv_cache_unified: layer  13: dev = CPU\n",
      "llama_kv_cache_unified: layer  14: dev = CPU\n",
      "llama_kv_cache_unified: layer  15: dev = CPU\n",
      "llama_kv_cache_unified: layer  16: dev = CPU\n",
      "llama_kv_cache_unified: layer  17: dev = CPU\n",
      "llama_kv_cache_unified: layer  18: dev = CPU\n",
      "llama_kv_cache_unified: layer  19: dev = CPU\n",
      "llama_kv_cache_unified: layer  20: dev = CPU\n",
      "llama_kv_cache_unified: layer  21: dev = CPU\n",
      "llama_kv_cache_unified: layer  22: dev = CPU\n",
      "llama_kv_cache_unified: layer  23: dev = CPU\n",
      "llama_kv_cache_unified: layer  24: dev = CPU\n",
      "llama_kv_cache_unified: layer  25: dev = CPU\n",
      "llama_kv_cache_unified: layer  26: dev = CPU\n",
      "llama_kv_cache_unified: layer  27: dev = CPU\n",
      "llama_kv_cache_unified:        CPU KV buffer size =   140.00 MiB\n",
      "llama_kv_cache_unified: size =  140.00 MiB (  5120 cells,  28 layers,  1/1 seqs), K (f16):   70.00 MiB, V (f16):   70.00 MiB\n",
      "llama_context: enumerating backends\n",
      "llama_context: backend_ptrs.size() = 1\n",
      "llama_context: max_nodes = 2704\n",
      "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "llama_context:        CPU compute buffer size =   302.75 MiB\n",
      "llama_context: graph nodes  = 1070\n",
      "llama_context: graph splits = 1\n",
      "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | \n",
      "Model metadata: {'qwen2.attention.head_count': '12', 'general.name': 'qwen2-1_5b-instruct', 'general.architecture': 'qwen2', 'qwen2.block_count': '28', 'qwen2.context_length': '32768', 'qwen2.attention.head_count_kv': '2', 'quantize.imatrix.dataset': '../sft_2406.txt', 'qwen2.embedding_length': '1536', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '151643', 'qwen2.feed_forward_length': '8960', 'tokenizer.ggml.padding_token_id': '151643', 'qwen2.rope.freq_base': '1000000.000000', 'qwen2.attention.layer_norm_rms_epsilon': '0.000001', 'tokenizer.ggml.eos_token_id': '151645', 'general.file_type': '2', 'tokenizer.ggml.model': 'gpt2', 'tokenizer.ggml.pre': 'qwen2', 'tokenizer.chat_template': \"{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n' }}{% endif %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}\", 'tokenizer.ggml.add_bos_token': 'false', 'quantize.imatrix.chunks_count': '1937', 'quantize.imatrix.file': '../Qwen2/gguf/qwen2-1_5b-imatrix/imatrix.dat', 'quantize.imatrix.entries_count': '196'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "' }}{% endif %}{{'<|im_start|>' + message['role'] + '\n",
      "' + message['content'] + '<|im_end|>' + '\n",
      "'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n",
      "' }}{% endif %}\n",
      "Using chat eos_token: <|im_end|>\n",
      "Using chat bos_token: <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "# qwen2-1_5b-instruct-q4_0\n",
    "llm = Llama(\n",
    "    model_path = \"../Models/qwen2-1_5b-instruct-q4_0.gguf\",\n",
    "    n_ctx = 5096,\n",
    "    n_threads = 8\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZsaWBlnq5MHc"
   },
   "source": [
    "---\n",
    "\n",
    "User-defined function to construct RAG prompt using the query from the user appended as the \"query\" and the top related crime descriptions appended as the context.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "4GqEN0hA5MHc"
   },
   "outputs": [],
   "source": [
    "def rag_generate(query, context):\n",
    "  prompt = f\"\"\"\n",
    "<|im_start|>system\n",
    "ನೀವು ಕರ್ನಾಟಕ ಪೊಲೀಸ್ ಇಲಾಖೆಗೆ ಸಹಾಯ ಮಾಡುವ AI ಸಹಾಯಕ.\n",
    "ನೀವು ಕೇವಲ FIR ಮಾಹಿತಿಯ ಆಧಾರದ ಮೇಲೆ ಉತ್ತರಿಸುತ್ತೀರಿ.\n",
    "<|im_end|>\n",
    "\n",
    "<|im_start|>user\n",
    "ಕೆಳಗಿನ FIR ವಿವರಗಳನ್ನು ಗಮನಿಸಿ.\n",
    "\n",
    "ನಿಯಮಗಳು:\n",
    "- FIR ವಿವರಗಳಲ್ಲಿ ಇಲ್ಲದ ಮಾಹಿತಿಯನ್ನು ಸೇರಿಸಬಾರದು\n",
    "- ಇಂಗ್ಲಿಷ್ ಬಳಸಬಾರದು\n",
    "- ಉತ್ತರ ಕನ್ನಡದಲ್ಲಿರಬೇಕು\n",
    "\n",
    "FIR ವಿವರಗಳು:\n",
    "{context}\n",
    "\n",
    "ಪ್ರಶ್ನೆ:\n",
    "{query}\n",
    "<|im_end|>\n",
    "\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "  output = llm(\n",
    "    prompt,\n",
    "    max_tokens = 300,\n",
    "    temperature = 0.15,\n",
    "    top_p = 0.9,\n",
    "    repeat_penalty = 1.1,\n",
    "    stop = [\"<|im_end|>\"]\n",
    ")\n",
    "\n",
    "  return output[\"choices\"][0][\"text\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "User-defined function to prepare the query and the context for the RAG\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "C7Nmv9yw5MHc"
   },
   "outputs": [],
   "source": [
    "def ask_fir_assistant(query, k = 2):\n",
    "    retrieved = semantic_search(query, k)\n",
    "    context = \"\\n\\n\".join(retrieved)\n",
    "    return rag_generate(query, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "SI24Hhga5MHc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =   62407.56 ms\n",
      "llama_perf_context_print: prompt eval time =   62405.53 ms /  3103 tokens (   20.11 ms per token,    49.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =   27028.70 ms /   299 runs   (   90.40 ms per token,    11.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   90637.18 ms /  3402 tokens\n",
      "llama_perf_context_print:    graphs reused =        288\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'FIR (Fire Investigation Report) is a document that records the investigation of an incident involving fire. It includes details about the fire, such as when it occurred, where it happened, and who was involved. The report also includes information about the cause of the fire, which could be due to negligence or arson.\\n\\nThe FIR in your provided text seems to be related to a fire that occurred on June 30th, 2016 at around 5:00 PM. It states that there were two people involved - a man named Kukuya (46) and a woman named Kukuya (46). The report also mentions that the fire started in the kitchen of a house located on the street called \"Kukuya Street\" near the town of Kukuya, which is in the district of Kukuya in the state of Karnataka. \\n\\nThe report further states that the man was injured and had to be taken to the hospital, but he did not survive. The woman was also injured but she survived. It mentions that the fire started due to negligence on the part of the man.\\n\\nThe FIR also includes information about the investigation process, which included a police officer named Kukuya (46) who arrived at the scene and took charge of the investigation. He stated that he had been informed by the woman that there was a fire in her house and that she needed medical attention. However, when he arrived at the scene, he found that the'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"ಮೊಬೈಲ್ ಫೋನ್ ಕಳವು\"\n",
    "ask_fir_assistant(query)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
